{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh941213/kaggle_NFL/blob/main/nfl_competition_xgboost_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost 란?\n",
        "- XGBoost는 Extreme Gradient Boosting의 약자이다.\n",
        "- Boosting 기법을 이용하여 구현한 알고리즘은 Gradient Boost 가 대표적인데\n",
        "이 알고리즘을 병렬 학습이 지원되도록 구현한 라이브러리가 XGBoost 이다.\n",
        "- Regression, Classification 문제를 모두 지원하며, 성능과 자원 효율이 좋아서, 인기 있게 사용되는 알고리즘이다."
      ],
      "metadata": {
        "id": "kNlKtJh7Aq2x"
      },
      "id": "kNlKtJh7Aq2x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost의 장점\n",
        "- GBM 대비 빠른 수행시간\n",
        "- 병렬 처리로 학습, 분류 속도가 빠르다.\n",
        "- 과적합 규제(Regularization)\n",
        "- 표준 GBM 경우 과적합 규제기능이 없으나, XGBoost는 자체에 과적합 규제 기능으로 강한 내구성 지닌다.\n",
        "- 분류와 회귀영역에서 뛰어난 예측 성능 발휘\n",
        "- 즉, CART(Classification and regression tree) 앙상블 모델을 사용\n",
        "- Early Stopping(조기 종료) 기능이 있음\n",
        "- 다양한 옵션을 제공하며 Customizing이 용이하다.\n",
        "\n",
        "\n",
        "참조 : https://wooono.tistory.com/97"
      ],
      "metadata": {
        "id": "0T35gzA1Av1K"
      },
      "id": "0T35gzA1Av1K"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle --upgrade # kaggle install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhaSexQQpov7",
        "outputId": "105465bc-9d82-419c-cea2-068941bccb35"
      },
      "id": "MhaSexQQpov7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (8.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/kaggle.json #kaggle json API"
      ],
      "metadata": {
        "id": "okc7j9U3pyOZ"
      },
      "id": "okc7j9U3pyOZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nfl-player-contact-detection #kaggle NFL data download\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3qjzgb9qEzW",
        "outputId": "f76fb059-dac6-41be-c36b-1cde568d319d"
      },
      "id": "R3qjzgb9qEzW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading nfl-player-contact-detection.zip to /content\n",
            "100% 3.83G/3.84G [02:57<00:00, 23.1MB/s]\n",
            "100% 3.84G/3.84G [02:57<00:00, 23.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "z= zipfile.ZipFile('titanic.zip')\n",
        "z.extractall() #unzip"
      ],
      "metadata": {
        "id": "1NgMOwYMu0AD"
      },
      "id": "1NgMOwYMu0AD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0722a1",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-12-07T03:20:24.054238Z",
          "iopub.status.busy": "2022-12-07T03:20:24.053352Z",
          "iopub.status.idle": "2022-12-07T03:20:25.867948Z",
          "shell.execute_reply": "2022-12-07T03:20:25.866895Z"
        },
        "papermill": {
          "duration": 1.821487,
          "end_time": "2022-12-07T03:20:25.870516",
          "exception": false,
          "start_time": "2022-12-07T03:20:24.049029",
          "status": "completed"
        },
        "tags": [],
        "id": "1d0722a1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "#환경설정 변수 \n",
        "class Config:\n",
        "    AUTHOR = \"colum2131\" #작성자 이름 \n",
        "\n",
        "    NAME = \"NFLC-\" + \"Exp001-simple-xgb-baseline\" # 프로젝트 네임\n",
        "\n",
        "    COMPETITION = \"nfl-player-contact-detection\" #대회 이름\n",
        "\n",
        "    seed = 42 # 랜덤시드 변수\n",
        "    num_fold = 5 # 교차검증에 사용되는 fold의 수다\n",
        "    \n",
        "    xgb_params = {  # XGBoost model 의 하이퍼 파라미터 \n",
        "        'objective': 'binary:logistic', # 손실함수를 나타낸다 : 이진분류의 경우 로지스틱\n",
        "        'eval_metric': 'auc', # 평가지표를 acurracy\n",
        "        'learning_rate':0.03, # 학습률을 나타내느 부동 소수점 변수 0.03 보통 우리가 배웠을땐 0.005 로 하긴했었다 수정해볼 필요 있어보인다\n",
        "        'tree_method':'hist' if not torch.cuda.is_available() else 'gpu_hist'\n",
        "    } # 트리구성 알고리즘을 나타내는 변수 : gpu 가 사용불가할때 gpu_hist 로 설정이 된다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cudf-cu11==22.12 rmm-cu11==22.12 --extra-index-url=https://pypi.ngc.nvidia.com/. #cudf 설치"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJVq7k4bkOyH",
        "outputId": "1798e953-8df0-40e5-e60f-e6b966aee5ca"
      },
      "id": "DJVq7k4bkOyH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com/.\n",
            "Collecting cudf-cu11==22.12\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/cudf-cu11/cudf_cu11-22.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rmm-cu11==22.12\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/rmm-cu11/rmm_cu11-22.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cubinlinker-cu11\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/cubinlinker-cu11/cubinlinker_cu11-0.3.0.post1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (4.5.0)\n",
            "Requirement already satisfied: pyarrow==9.0.0 in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (9.0.0)\n",
            "Requirement already satisfied: pandas<1.6.0dev0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (1.3.5)\n",
            "Collecting protobuf<3.21.0a0,>=3.20.1\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (23.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (2023.1.0)\n",
            "Collecting cuda-python<12.0,>=11.7.1\n",
            "  Downloading cuda_python-11.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (1.21.6)\n",
            "Collecting ptxcompiler-cu11\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/ptxcompiler-cu11/ptxcompiler_cu11-0.7.0.post1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cupy-cuda11x in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (11.0.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (5.3.0)\n",
            "Requirement already satisfied: numba>=0.56.2 in /usr/local/lib/python3.8/dist-packages (from cudf-cu11==22.12) (0.56.4)\n",
            "Collecting nvtx>=0.2.1\n",
            "  Downloading nvtx-0.2.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.6/453.6 KB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from cuda-python<12.0,>=11.7.1->cudf-cu11==22.12) (0.29.33)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.56.2->cudf-cu11==22.12) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.56.2->cudf-cu11==22.12) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.56.2->cudf-cu11==22.12) (0.39.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.0->cudf-cu11==22.12) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.0->cudf-cu11==22.12) (2022.7.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.8/dist-packages (from cupy-cuda11x->cudf-cu11==22.12) (0.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas<1.6.0dev0,>=1.0->cudf-cu11==22.12) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.56.2->cudf-cu11==22.12) (3.13.0)\n",
            "Installing collected packages: ptxcompiler-cu11, nvtx, cubinlinker-cu11, protobuf, cuda-python, rmm-cu11, cudf-cu11\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cubinlinker-cu11-0.3.0.post1 cuda-python-11.8.1 cudf-cu11-22.12.0 nvtx-0.2.5 protobuf-3.20.3 ptxcompiler-cu11-0.7.0.post1 rmm-cu11-22.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rapidsai/cuml.git # cuml git clone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXc_KEVzn1pm",
        "outputId": "1265a381-77f8-423a-b1de-8a04dbac76b5"
      },
      "id": "yXc_KEVzn1pm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuml'...\n",
            "remote: Enumerating objects: 126864, done.\u001b[K\n",
            "remote: Counting objects: 100% (832/832), done.\u001b[K\n",
            "remote: Compressing objects: 100% (495/495), done.\u001b[K\n",
            "remote: Total 126864 (delta 342), reused 768 (delta 321), pack-reused 126032\u001b[K\n",
            "Receiving objects: 100% (126864/126864), 153.93 MiB | 16.52 MiB/s, done.\n",
            "Resolving deltas: 100% (97842/97842), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cuml # cuml install 인데 cuda 버전과 상이해서 오류가나는 것으로 생각된다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMdY7TKnn6Pd",
        "outputId": "298b766a-f750-48ea-efb3-b45e0adbf4bb"
      },
      "id": "vMdY7TKnn6Pd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cuml\n",
            "  Using cached cuml-0.6.1.post1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: cuml\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cuml (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cuml\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cuml\n",
            "Failed to build cuml\n",
            "Installing collected packages: cuml\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for cuml\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for cuml ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m cuml\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cudf\n",
        "!pip install cupy\n"
      ],
      "metadata": {
        "id": "N4nQvl6PsWKA",
        "outputId": "92b23841-7b53-4977-835b-4949e19529e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N4nQvl6PsWKA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cudf\n",
            "  Downloading cudf-0.6.1.post1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: cudf\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cudf (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cudf\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cudf\n",
            "Failed to build cudf\n",
            "Installing collected packages: cudf\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for cudf\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for cudf ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m cudf\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cupy\n",
            "  Downloading cupy-11.5.0.tar.gz (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from cupy) (1.21.6)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.8/dist-packages (from cupy) (0.8.1)\n",
            "Building wheels for collected packages: cupy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234c09fd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-07T03:20:25.879396Z",
          "iopub.status.busy": "2022-12-07T03:20:25.878954Z",
          "iopub.status.idle": "2022-12-07T03:20:29.656215Z",
          "shell.execute_reply": "2022-12-07T03:20:29.655211Z"
        },
        "papermill": {
          "duration": 3.784112,
          "end_time": "2022-12-07T03:20:29.658809",
          "exception": false,
          "start_time": "2022-12-07T03:20:25.874697",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "234c09fd",
        "outputId": "7ab03e81-76a0-4286-b5e1-0037ccecf698"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6cb5a83b77ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mForestInference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cuml'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import subprocess # 하위 프로세서를 다루는 모듈\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from IPython.display import Video, display\n",
        "\n",
        "from scipy.optimize import minimize #과학적인 계산을 위한 모듈\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import GroupKFold #모델선택을 위한 모듈 Group Kfold\n",
        "from sklearn.metrics import ( # 평가지표를 위한 모델\n",
        "    roc_auc_score,\n",
        "    matthews_corrcoef,\n",
        ")\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    import cupy #numpy 와 유사한 인터페이스를 가지는 Gpu용 배열 라이브러리\n",
        "    import cudf # gpu를 사용하여 데이터 프레임을 조작하는 라이브러리 \n",
        "    from cuml import ForestInference # gpu를 사용하여 머신러닝 알고리즘을 실행하는 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cuml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqkEE1b5mxse",
        "outputId": "4fe890e4-e80c-4eae-f5bd-c9810ebf51f1"
      },
      "id": "bqkEE1b5mxse",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cuml\n",
            "  Using cached cuml-0.6.1.post1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: cuml\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cuml (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cuml\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cuml\n",
            "Failed to build cuml\n",
            "Installing collected packages: cuml\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for cuml\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for cuml ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m cuml\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7748a972",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-07T03:20:29.666474Z",
          "iopub.status.busy": "2022-12-07T03:20:29.665554Z",
          "iopub.status.idle": "2022-12-07T03:20:29.672685Z",
          "shell.execute_reply": "2022-12-07T03:20:29.671840Z"
        },
        "papermill": {
          "duration": 0.013001,
          "end_time": "2022-12-07T03:20:29.674790",
          "exception": false,
          "start_time": "2022-12-07T03:20:29.661789",
          "status": "completed"
        },
        "tags": [],
        "id": "7748a972"
      },
      "outputs": [],
      "source": [
        "def setup(cfg): # 환경설정 함수\n",
        "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #현재 사용가능한 디바이스를 확인하고 gpu 가 사용 가능하다면 쿠다를 아니면 CPU\n",
        "    \n",
        "    # set dirs\n",
        "    cfg.INPUT = f'../input/{cfg.COMPETITION}'   #AUTHOR = \"colum2131\" #작성자 이름  NAME = \"NFLC-\" + \"Exp001-simple-xgb-baseline\" # 프로젝트 네임 #COMPETITION = \"nfl-player-contact-detection\" #대회 이름\n",
        "    cfg.EXP = cfg.NAME  #\"NFLC-\" + \"Exp001-simple-xgb-baseline\"\n",
        "    cfg.OUTPUT_EXP = cfg.NAME #\"NFLC-\" + \"Exp001-simple-xgb-baseline\"\n",
        "    cfg.SUBMISSION = './'\n",
        "    cfg.DATASET = '../input/'\n",
        "\n",
        "    cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model') #NFLC-\" + \"Exp001-simple-xgb-baseline/model\n",
        "    cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')     #NFLC-\" + \"Exp001-simple-xgb-baseline/fig\n",
        "    cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds') #NFLC-\" + \"Exp001-simple-xgb-baseline/preds\n",
        "\n",
        "    # make dirs\n",
        "    for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n",
        "        os.makedirs(d, exist_ok=True)\n",
        "        \n",
        "    return cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a621bec",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-07T03:20:29.681765Z",
          "iopub.status.busy": "2022-12-07T03:20:29.681473Z",
          "iopub.status.idle": "2022-12-07T03:20:29.699855Z",
          "shell.execute_reply": "2022-12-07T03:20:29.698868Z"
        },
        "papermill": {
          "duration": 0.024362,
          "end_time": "2022-12-07T03:20:29.701824",
          "exception": false,
          "start_time": "2022-12-07T03:20:29.677462",
          "status": "completed"
        },
        "tags": [],
        "id": "1a621bec"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# function\n",
        "# ==============================\n",
        "# ref: https://www.kaggle.com/code/robikscube/nfl-player-contact-detection-getting-started\n",
        "\n",
        "\n",
        "def add_contact_id(df): # df game_play, step, nfl_player_id_1, nfl_player_id_2 열을 조합하여 contact_id 를 만들어낸다\n",
        "    # Create contact ids  \n",
        "    df[\"contact_id\"] = (df[\"game_play\"]+ \"_\" + df[\"step\"].astype(\"str\")+ \"_\" + df[\"nfl_player_id_1\"].astype(\"str\") + \"_\" + df[\"nfl_player_id_2\"].astype(\"str\"))\n",
        "    return df\n",
        "\n",
        "def expand_contact_id(df):\n",
        "    \"\"\"\n",
        "    contact_id를 별도의 열로 분할합니다.\n",
        "    \"\"\"\n",
        "    df[\"game_play\"] = df[\"contact_id\"].str[:12] # contact_id 에서 열에서 12자리를 가져온다\n",
        "    df[\"step\"] = df[\"contact_id\"].str.split(\"_\").str[-3].astype(\"int\") # 열을 _로 분리한후 뒤에서 3번째 정수형으로 변환하여 가져온다\n",
        "    df[\"nfl_player_id_1\"] = df[\"contact_id\"].str.split(\"_\").str[-2] # 열을 _로 분리후 뒤에서 2번째 문자열로 가져온다 플레이어 ID1\n",
        "    df[\"nfl_player_id_2\"] = df[\"contact_id\"].str.split(\"_\").str[-1] # 열을 _로 분리후 뒤에서 1번째 문자열로 가져온다 플레이어 ID2\n",
        "    return df #새로만든 df 데이터 프레임을 리턴해준다\n",
        "\n",
        "\n",
        "# cross validation \n",
        "                   #(train 'contact', 'game_play', cfg.num_fold)\n",
        "def get_groupkfold(train, target_col, group_col, n_splits): # train 데이터와 target_col, group_col, n_splits를 입력값으로 받습니다.\n",
        "    kf = GroupKFold(n_splits=n_splits) #GroupKFold 객체를 생성하여 train 데이터를 group_col로 그룹화하고 n_splits 수 만큼 fold를 나누는 교차 검증을 수행합니다.\n",
        "    generator = kf.split(train, train[target_col], train[group_col]) #target_col 타겟변수의 열이 름 지정 , group_col 그룹별 교차검증 위해 사용\n",
        "    fold_series = []\n",
        "    for fold, (idx_train, idx_valid) in enumerate(generator): # fold별로 validation set의 인덱스를 저장하여 fold_series 리스트에 추가합니다.\n",
        "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
        "    fold_series = pd.concat(fold_series).sort_index() # 마지막으로 fold_series를 concatenate하고 인덱스를 정렬하여 반환합니다.\n",
        "    return fold_series \n",
        "\n",
        "# xgboost code\n",
        "#fit_xgboost(cfg, train_X, train_y, cfg.xgb_params, add_suffix=\"_xgb_1st\")\n",
        "def fit_xgboost(cfg, X, y, params, add_suffix=''): #환경변수 , Train X ,Train y , params , 모델 이름에 추가할 접미사?\n",
        "    \"\"\"\n",
        "    xgb_params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'auc',\n",
        "        'learning_rate':0.01,\n",
        "        'tree_method':'gpu_hist'\n",
        "    }\n",
        "    \"\"\"\n",
        "   \n",
        "    oof_pred = np.zeros(len(y), dtype=np.float32)       #배열은 XGBoost 모델의 훈련 중 생성된 out-of-fold 예측값을 저장하는 데 사용됩니다.\n",
        "    for fold in sorted(cfg.folds.unique()): # 1. 현재 fold에 해당하는 인덱스로 학습 데이터와 검증 데이터를 나눕니다.\n",
        "        if fold == -1: continue\n",
        "        idx_train = (cfg.folds!=fold)\n",
        "        idx_valid = (cfg.folds==fold)\n",
        "        x_train, y_train = X[idx_train], y[idx_train]\n",
        "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
        "        display(pd.Series(y_valid).value_counts())\n",
        "\n",
        "        xgb_train = xgb.DMatrix(x_train, label=y_train) #2. 나눠진 학습/검증 데이터를 xgboost에서 사용할 수 있는 형태로 변환합니다.\n",
        "        xgb_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "        evals = [(xgb_train,'train'),(xgb_valid,'eval')]\n",
        "\n",
        "        model = xgb.train( # 3. xgboost 모델을 학습합니다.\n",
        "            params,\n",
        "            xgb_train,\n",
        "            num_boost_round=10_000, #100번중에 계산이 안됨\n",
        "            early_stopping_rounds=100,\n",
        "            evals=evals,\n",
        "            verbose_eval=100,\n",
        "        )\n",
        "\n",
        "        model_path = os.path.join(cfg.EXP_MODEL, f'xgb_fold{fold}{add_suffix}.model') # 모델이 저장될 경로\n",
        "        model.save_model(model_path)#4. 학습된 모델을 디스크에 저장합니다.\n",
        "\n",
        "        if not torch.cuda.is_available(): #\n",
        "            model = xgb.Booster().load_model(model_path)   #xgb.Booster().load_model() 메서드를 사용하여 지정된 경로에서 훈련된 XGBoost 모델을 로드하고 \n",
        "        else:\n",
        "            model = ForestInference.load(model_path, output_class=True, model_type='xgboost') #그렇지 않으면 ForestInference.load() 메서드를 사용하여 지정된 매개변수로 모델을 로드합니다.\n",
        "        pred_i = model.predict_proba(x_valid)[:, 1]        #그런 다음 모델.predict_proba() 메서드를 사용하여 검증 세트 x_valid에서 예측을 수행하고 [:, 1]로 \n",
        "        oof_pred[x_valid.index] = pred_i                   #결과를 슬라이스하여 클래스 1의 확률을 추출합니다. 예측된 확률은 x_valid.index를 사용하여 oof_pred의 해당 인덱스에 할당됩니다.\n",
        "        score = round(roc_auc_score(y_valid, pred_i), 5) \n",
        "        print(f'Performance of the prediction: {score}\\n') #모델의 성능은 roc_auc_score() 함수를 사용하여 true 라벨인 y_valid와 예측된 확률 pred_i로 평가되며 결과는 소수점 5 자리로 표시됩니다.\n",
        "        del model; gc.collect()                            #마지막으로, 로드된 모델은 del model 및 gc.collect()를 사용하여 삭제되고 메모리가 해제됩니다.\n",
        "\n",
        "    np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred{add_suffix}'), oof_pred) #np.save를 사용하여 배열을 지정된경로에 저장하고 acc함수를 사용하여 레이블과 y와 예측간 AUC 점수를 계산\n",
        "    score = round(roc_auc_score(y, oof_pred), 5) #계산된 점수는 5자리로 반올림하여 콘솔에 출력됩니다.\n",
        "    print(f'All Performance of the prediction: {score}') \n",
        "    return oof_pred #oof_pred 배열 반환해준다\n",
        "\n",
        "\n",
        "# pred_xgboost(test_X, cfg.EXP_MODEL, add_suffix=\"_xgb_1st\") \n",
        "def pred_xgboost(X, data_dir, add_suffix=''):\n",
        "    models = glob(os.path.join(data_dir, f'xgb_fold*{add_suffix}.model'))   #이 함수는 입력 특징 X와 디렉토리 경로 data_dir를 입력으로 받고, 디렉토리에 저장된 XGBoost 모델의 예측값을 반환합니다. add_suffix 인수는 파일 이름에 특정 접미사가 있는 모델을 선택할 수 있도록 합니다.\n",
        "    if not torch.cuda.is_available():\n",
        "         models = [xgb.Booster().load_model(model_path) for model in models]\n",
        "    else:\n",
        "        models = [ForestInference.load(model, output_class=True, model_type='xgboost') for model in models]\n",
        "    preds = np.array([model.predict_proba(X)[:, 1] for model in models])\n",
        "    preds = np.mean(preds, axis=0)\n",
        "    return preds #이 함수는 XGBoost 모델이 이진 결과를 예측하도록 학습되었다고 가정합니다 (예: 0 또는 1). 이 함수는 확률을 추출하기 위해 [:, 1] 인덱싱을 사용하기 때문에, 모델이 다중 클래스를 예측하도록 학습된 경우 예측을 올바르게 처리하기 위해 수정해야 할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d635f79",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-07T03:20:29.708600Z",
          "iopub.status.busy": "2022-12-07T03:20:29.708314Z",
          "iopub.status.idle": "2022-12-07T03:20:42.334791Z",
          "shell.execute_reply": "2022-12-07T03:20:42.333804Z"
        },
        "papermill": {
          "duration": 12.63249,
          "end_time": "2022-12-07T03:20:42.337211",
          "exception": false,
          "start_time": "2022-12-07T03:20:29.704721",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "2d635f79",
        "outputId": "93462b14-9814-4248-f8d9-e68afa0173b4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-67dc9c201fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_player_tracking.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mte_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_player_tracking.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# tr_helmets = cudf.read_csv(os.path.join(cfg.INPUT, 'train_baseline_helmets.csv'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mlibnvtx_push_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mlibnvtx_pop_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/io/csv.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, prefix, mangle_dupe_cols, dtype, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, dayfirst, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, comment, delim_whitespace, byte_range, use_python_file_object, storage_options, bytes_per_thread)\u001b[0m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     filepath_or_buffer, compression = ioutils.get_reader_filepath_or_buffer(\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mpath_or_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/utils/ioutils.py\u001b[0m in \u001b[0;36mget_reader_filepath_or_buffer\u001b[0;34m(path_or_data, compression, mode, fs, iotypes, use_python_file_object, open_file_options, allow_raw_text_input, storage_options, bytes_per_thread)\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mpath_or_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_raw_text_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m                     raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1663\u001b[0m                         \u001b[0;34mf\"{path_or_data} could not be resolved to any files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m                     )\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: ../input/nfl-player-contact-detection/train_player_tracking.csv could not be resolved to any files"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# read data\n",
        "# ==============================\n",
        "cfg = setup(Config)\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    tr_tracking = pd.read_csv(os.path.join(cfg.INPUT, 'train_player_tracking.csv'), parse_dates=[\"datetime\"])\n",
        "    te_tracking = pd.read_csv(os.path.join(cfg.INPUT, 'test_player_tracking.csv'), parse_dates=[\"datetime\"])\n",
        "    # tr_helmets = pd.read_csv(os.path.join(cfg.INPUT, 'train_baseline_helmets.csv'))\n",
        "    # te_helmets = pd.read_csv(os.path.join(cfg.INPUT, 'test_baseline_helmets.csv'))\n",
        "    # tr_video_metadata = pd.read_csv(os.path.join(cfg.INPUT, 'train_video_metadata.csv'))\n",
        "    # te_video_metadata = pd.read_csv(os.path.join(cfg.INPUT, 'test_video_metadata.csv'))\n",
        "    sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n",
        "\n",
        "    train = pd.read_csv(os.path.join(cfg.INPUT, 'train_labels.csv'), parse_dates=[\"datetime\"])\n",
        "    test = expand_contact_id(sub)\n",
        "    \n",
        "else:\n",
        "    tr_tracking = cudf.read_csv(os.path.join(cfg.INPUT, 'train_player_tracking.csv'), parse_dates=[\"datetime\"])\n",
        "    te_tracking = cudf.read_csv(os.path.join(cfg.INPUT, 'test_player_tracking.csv'), parse_dates=[\"datetime\"])\n",
        "    # tr_helmets = cudf.read_csv(os.path.join(cfg.INPUT, 'train_baseline_helmets.csv'))\n",
        "    # te_helmets = cudf.read_csv(os.path.join(cfg.INPUT, 'test_baseline_helmets.csv'))\n",
        "    # tr_video_metadata = cudf.read_csv(os.path.join(cfg.INPUT, 'train_video_metadata.csv'))\n",
        "    # te_video_metadata = cudf.read_csv(os.path.join(cfg.INPUT, 'test_video_metadata.csv'))\n",
        "    sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n",
        "\n",
        "    train = cudf.read_csv(os.path.join(cfg.INPUT, 'train_labels.csv'), parse_dates=[\"datetime\"])\n",
        "    test = cudf.DataFrame(expand_contact_id(sub))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29e474b3",
      "metadata": {
        "papermill": {
          "duration": 0.002636,
          "end_time": "2022-12-07T03:20:42.342986",
          "exception": false,
          "start_time": "2022-12-07T03:20:42.340350",
          "status": "completed"
        },
        "tags": [],
        "id": "29e474b3"
      },
      "source": [
        "The following code is used to create the features.  \n",
        "Basically, the numerical features contained in player_tracking.csv are merged into player_id_1 and player_id_2 respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdaf6df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-07T03:20:42.349847Z",
          "iopub.status.busy": "2022-12-07T03:20:42.349497Z",
          "iopub.status.idle": "2022-12-07T03:20:50.168690Z",
          "shell.execute_reply": "2022-12-07T03:20:50.167603Z"
        },
        "papermill": {
          "duration": 7.825436,
          "end_time": "2022-12-07T03:20:50.171042",
          "exception": false,
          "start_time": "2022-12-07T03:20:42.345606",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "1bdaf6df",
        "outputId": "1a0b2801-bbdf-4016-af3e-2368e5ad23c5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-52cbd650f6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m'direction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'orientation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acceleration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sa'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m ]\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_tracking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_tracking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# feature engineering\n",
        "# ==============================\n",
        "\n",
        "# 데이터셋 목적에 맞게 변환해주는 작업같음\n",
        "\n",
        "def create_features(df, tr_tracking, merge_col=\"step\", use_cols=[\"x_position\", \"y_position\"]):\n",
        "    output_cols = []\n",
        "    df_combo = (\n",
        "        df.astype({\"nfl_player_id_1\": \"str\"}) #type 변경 nf1_player_Id_1 : str\n",
        "        .merge( tr_tracking.astype({\"nfl_player_id\": \"str\"})[[\"game_play\", merge_col, \"nfl_player_id\",] + use_cols],\n",
        "            left_on=[\"game_play\", merge_col, \"nfl_player_id_1\"],\n",
        "            right_on=[\"game_play\", merge_col, \"nfl_player_id\"],\n",
        "            how=\"left\",\n",
        "        ) # \n",
        "        .rename(columns={c: c+\"_1\" for c in use_cols})\n",
        "        .drop(\"nfl_player_id\", axis=1)\n",
        "        .merge(\n",
        "            tr_tracking.astype({\"nfl_player_id\": \"str\"})[\n",
        "                [\"game_play\", merge_col, \"nfl_player_id\"] + use_cols\n",
        "            ],\n",
        "            left_on=[\"game_play\", merge_col, \"nfl_player_id_2\"],\n",
        "            right_on=[\"game_play\", merge_col, \"nfl_player_id\"],\n",
        "            how=\"left\",\n",
        "        )\n",
        "        .drop(\"nfl_player_id\", axis=1)\n",
        "        .rename(columns={c: c+\"_2\" for c in use_cols})\n",
        "        .sort_values([\"game_play\", merge_col, \"nfl_player_id_1\", \"nfl_player_id_2\"])\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    output_cols += [c+\"_1\" for c in use_cols]\n",
        "    output_cols += [c+\"_2\" for c in use_cols]\n",
        "    \n",
        "    if (\"x_position\" in use_cols) & (\"y_position\" in use_cols):\n",
        "        index = df_combo['x_position_2'].notnull()\n",
        "        if torch.cuda.is_available():\n",
        "            index = index.to_array()\n",
        "        distance_arr = np.full(len(index), np.nan)\n",
        "        tmp_distance_arr = np.sqrt(\n",
        "            np.square(df_combo.loc[index, \"x_position_1\"] - df_combo.loc[index, \"x_position_2\"])\n",
        "            + np.square(df_combo.loc[index, \"y_position_1\"]- df_combo.loc[index, \"y_position_2\"])\n",
        "        )\n",
        "        if torch.cuda.is_available():\n",
        "            tmp_distance_arr = tmp_distance_arr.to_array()\n",
        "        distance_arr[index] = tmp_distance_arr\n",
        "        df_combo['distance'] = distance_arr\n",
        "        output_cols += [\"distance\"]\n",
        "        \n",
        "    df_combo['G_flug'] = (df_combo['nfl_player_id_2']==\"G\")\n",
        "    output_cols += [\"G_flug\"]\n",
        "    return df_combo, output_cols\n",
        "\n",
        "\n",
        "use_cols = [\n",
        "    'x_position', 'y_position', 'speed', 'distance',\n",
        "    'direction', 'orientation', 'acceleration', 'sa'\n",
        "]\n",
        "train, feature_cols = create_features(train, tr_tracking, use_cols=use_cols)\n",
        "test, feature_cols = create_features(test, te_tracking, use_cols=use_cols)\n",
        "if torch.cuda.is_available():\n",
        "    train = train.to_pandas()\n",
        "    test = test.to_pandas()\n",
        "\n",
        "display(train)\n",
        "'''\n",
        "주어진 데이터프레임(df)과 위치 추적 데이터프레임(tr_tracking)을 조합하여 새로운 특징(feature)들을 만드는 함수 create_features를 정의합니다. \n",
        "create_features 함수는 데이터프레임(df_combo)과 출력 열 목록(output_cols)을 반환합니다.\n",
        "\n",
        "먼저, df_combo는 다음 단계(step) 또는 병합 열(merge_col)과 nfl_player_id_1 열을 기준으로 데이터프레임(df)과 위치 추적 데이터프레임(tr_tracking)을 병합합니다. \n",
        "이후, use_cols에서 지정한 열에 대해 \"_1\"을 추가한 이름으로 열 이름을 바꾸고, nfl_player_id 열을 삭제합니다.\n",
        "\n",
        "그 다음, nfl_player_id_2 열을 기준으로 데이터프레임(df_combo)과 위치 추적 데이터프레임(tr_tracking)을 병합합니다. 이후, use_cols에서 지정한 열에 대해 \"_2\"를 추가한 이름으로 열 이름을 바꾸고, \n",
        "nfl_player_id 열을 삭제합니다.\n",
        "\n",
        "그리고 마지막으로, game_play, merge_col, nfl_player_id_1 및 nfl_player_id_2 열을 기준으로 데이터프레임(df_combo)을 정렬합니다.\n",
        " 만약 use_cols에 \"x_position\"과 \"y_position\"이 포함되어 있다면, 데이터프레임(df_combo)에 \"distance\" 열을 추가하고, nfl_player_id_2가 \"G\"인 경우 \"G_flug\" 열을 추가합니다.\n",
        "\n",
        "마지막으로, create_features 함수는 데이터프레임(df_combo)과 출력 열 목록(output_cols)을 반환하고, \n",
        "use_cols에서 지정한 열을 사용하여 훈련 데이터(train)와 테스트 데이터(test)에 대해 create_features 함수를 호출합니다. 마지막으로, train 데이터프레임을 출력합니다.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db51ea7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-07T03:20:50.179141Z",
          "iopub.status.busy": "2022-12-07T03:20:50.178853Z",
          "iopub.status.idle": "2022-12-07T03:25:08.974229Z",
          "shell.execute_reply": "2022-12-07T03:25:08.973203Z"
        },
        "papermill": {
          "duration": 258.802423,
          "end_time": "2022-12-07T03:25:08.976971",
          "exception": false,
          "start_time": "2022-12-07T03:20:50.174548",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "0db51ea7",
        "outputId": "fa2a8d2c-e3d2-4d29-c59b-4e5038f5db61"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7b55ed12c462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# training & inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ==============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contact'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# training & inference\n",
        "# ==============================\n",
        "train_X = train[feature_cols] #create_features 함수를 사용하여 피쳐 컬럼을 선택하고, train_X와 test_X에 할당합니다.\n",
        "test_X = test[feature_cols]\n",
        "train_y = train['contact'] #타겟 변수 contact를 train_y에 할당합니다.\n",
        "cfg.folds = get_groupkfold(train, 'contact', 'game_play', cfg.num_fold) #get_groupkfold 함수를 사용하여 train 데이터셋에서 game_play을 그룹화 변수로 사용하여 그룹 k-폴드 교차 검증을 수행합니다. 결과적인 폴드는 CSV 파일로 저장됩니다.\n",
        "cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'), index=False)#결과적인 폴드는 CSV 파일로 저장됩니다.\n",
        "\n",
        "oof_pred = fit_xgboost(cfg, train_X, train_y, cfg.xgb_params, add_suffix=\"_xgb_1st\") #fit_xgboost 함수를 사용하여 지정된 하이퍼파라미터 cfg.xgb_params를 사용하여 train_X와 train_y 데이터를 기반으로 XGBoost 모델을 학습합니다. 결과적으로 나온 교차 검증 예측은 oof_pred에 할당됩니다.\n",
        "sub_pred = pred_xgboost(test_X, cfg.EXP_MODEL, add_suffix=\"_xgb_1st\") #pred_xgboost 함수를 사용하여 학습된 XGBoost 모델을 사용하여 test_X 데이터에 대한 예측을 생성합니다. 결과적인 예측은 sub_pred에 할당됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2808b071",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-07T03:25:08.994437Z",
          "iopub.status.busy": "2022-12-07T03:25:08.994130Z",
          "iopub.status.idle": "2022-12-07T03:25:53.504217Z",
          "shell.execute_reply": "2022-12-07T03:25:53.503107Z"
        },
        "papermill": {
          "duration": 44.530134,
          "end_time": "2022-12-07T03:25:53.514767",
          "exception": false,
          "start_time": "2022-12-07T03:25:08.984633",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "2808b071",
        "outputId": "78f2f000-97d7-495a-d177-49340b322918"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-18a98e48a479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nelder-mead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contact'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_pred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         return _minimize_neldermead(fun, x0, args, callback, bounds=bounds,\n\u001b[0m\u001b[1;32m    612\u001b[0m                                     **options)\n\u001b[1;32m    613\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mfsim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-18a98e48a479>\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x_list)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ==============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contact'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_pred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# optimize\n",
        "# ==============================\n",
        "#목적 함수정의\n",
        "def func(x_list):\n",
        "    score = matthews_corrcoef(train['contact'], oof_pred>x_list[0])\n",
        "    return -score\n",
        "#초기값 설정 및 최적화 수행\n",
        "x0 = [0.5]\n",
        "result = minimize(func, x0,  method=\"nelder-mead\")\n",
        "#초기값 설정 및 최적화 수행\n",
        "cfg.threshold = result.x[0]\n",
        "print(\"score:\", round(matthews_corrcoef(train['contact'], oof_pred>cfg.threshold), 5))\n",
        "print(\"threshold\", round(cfg.threshold, 5))\n",
        "#결과 예측\n",
        "test = add_contact_id(test)\n",
        "test['contact'] = (sub_pred > cfg.threshold).astype(int)\n",
        "test[['contact_id', 'contact']].to_csv('submission.csv', index=False)\n",
        "display(test[['contact_id', 'contact']].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_4ZOjhLAoQgF"
      },
      "id": "_4ZOjhLAoQgF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 339.248779,
      "end_time": "2022-12-07T03:25:55.548222",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-12-07T03:20:16.299443",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}